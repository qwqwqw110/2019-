{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8830041263275684\n",
      "0.8497474747474748\n",
      "0.8579044412377747\n",
      "0.8721941638608306\n",
      "0.8703803912137246\n",
      "0.8435445727112393\n",
      "0.8814534231200897\n",
      "0.8441320785070785\n",
      "0.8560066763191765\n",
      "0.8804898648648649\n",
      "ave Auc : 0.8638857212909821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/qw/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "\n",
    "# 保存训练好的模型\n",
    "def storeModel(MyModel, fileName):\n",
    "    fw = open(fileName, 'wb')\n",
    "    pickle.dump(MyModel, fw)\n",
    "    fw.close()\n",
    "\n",
    "# 读取模型\n",
    "def loadModel(fileName):\n",
    "    fr = open(fileName, 'rb')\n",
    "    MyModel = pickle.load(fr)\n",
    "    fr.close()\n",
    "    return MyModel\n",
    "\n",
    "# 过滤emoji\n",
    "def filterFace(destStr):\n",
    "    try:\n",
    "        p = re.compile(u'([[\\U00010000-\\U0010ffff])')\n",
    "    except re.error:\n",
    "        p = re.compile(u'([\\uD800-\\uDBFF][\\uDC00-\\uDFFF])')\n",
    "\n",
    "    t = p.findall(destStr)\n",
    "    return list(set(t))\n",
    "\n",
    "\n",
    "# 过滤类似 :)  :(的表情\n",
    "def filterFace1(destStr):\n",
    "    p = re.compile(\":\\)\")\n",
    "    q = re.compile(\":\\(\")\n",
    "    t1 = list(p.findall(destStr))\n",
    "    t2 = list(q.findall(destStr))\n",
    "\n",
    "    if len(t1) < 1:\n",
    "        t = t2\n",
    "    else:\n",
    "        t = t1\n",
    "    return t\n",
    "\n",
    "\n",
    "# 预处理文本信息，数据清洗\n",
    "def proReview(dataSet):\n",
    "    # 缺失项统计\n",
    "    # print(\"null num :\", trainData.isnull().sum())\n",
    "    # 表情处理\n",
    "    emjoy = []\n",
    "    for words in dataSet['review']:\n",
    "        emjoy.append(filterFace(words))\n",
    "\n",
    "    emjoy1 = []\n",
    "    for words in dataSet['review']:\n",
    "        emjoy1.append(filterFace1(words))\n",
    "\n",
    "    for i in range(len(emjoy)):\n",
    "        emjoy[i].extend(tok for tok in emjoy1[i])\n",
    "\n",
    "    # 去除字符串中的非字母 数字 下划线 空格\n",
    "    dataSet['review'] = dataSet['review'].str.replace('[^\\w\\s]', ' ')\n",
    "    dataSet['review'] = dataSet['review'].str.replace('[0-9]', '')\n",
    "    # 将所有的大写转化为小写\n",
    "    dataSet['review'] = dataSet['review'].apply(lambda sen: \" \".join(x.lower() for x in sen.split() if len(x) > 0))\n",
    "    dat = []\n",
    "    for i in range(len(dataSet['review'])):\n",
    "        strTemp = dataSet['review'][i] + ' '.join(emjoy[i])\n",
    "        dat.append(strTemp)\n",
    "    '''\n",
    "    # 常见词去除\n",
    "    freq = pd.Series(' '.join(dataSet['review']).split()).value_counts()[:5]\n",
    "    delFreq = list(freq.index)\n",
    "    dataSet['review'] = dataSet['review'].apply(lambda x: ' '.join(word for word in x.split() if word not in delFreq))\n",
    "\n",
    "\n",
    "    # 稀缺词去除\n",
    "    freq = pd.Series(' '.join(trainData['review']).split()).value_counts()[-10:]\n",
    "    delFreq = list(freq.index)\n",
    "    trainData['review'] = trainData['review'].apply(lambda x: ' '.join(word for word in x.split() if word not in delFreq))\n",
    "    '''\n",
    "    # 将表情添加进去\n",
    "    \n",
    "    return pd.Series(dat)\n",
    "\n",
    "# 预处理数据\n",
    "def loadData():\n",
    "    trainData = pd.read_csv('train.csv', lineterminator='\\n')\n",
    "    testData = pd.read_csv('20190506_test.csv', lineterminator='\\n')\n",
    "\n",
    "    trainDataMat = proReview(trainData)\n",
    "    testDataMat = proReview(testData)\n",
    "\n",
    "    m = trainDataMat.shape[0]\n",
    "    # get babels\n",
    "    labelsText = trainData['label']\n",
    "    labels = np.ones((m, 1))\n",
    "    for i in range(m):\n",
    "        if labelsText[i] == 'Negative':\n",
    "            labels[i] = 0\n",
    "\n",
    "    return trainDataMat, testDataMat, labels\n",
    "\n",
    "# 加载数据\n",
    "trainDataSet, testDataSet, labels = loadData()\n",
    "trainLen = len(trainDataSet)\n",
    "\n",
    "# TFI-TF 关键词提取以及分词\n",
    "tfidf_vec = TfidfVectorizer(max_df=0.7, min_df=2, ngram_range=(1,3))\n",
    "tfidf_matrix = tfidf_vec.fit_transform(trainDataSet.astype('U').tolist() + testDataSet.astype('U').tolist())\n",
    "\n",
    "trainMat = tfidf_matrix[:trainLen]\n",
    "testMat = tfidf_matrix[trainLen:]\n",
    "trainLabels = labels\n",
    "\n",
    "# K fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "MNB = MultinomialNB(alpha=0.7)\n",
    "sfd = StratifiedKFold(n_splits=10) # 10折验证\n",
    "sfd.get_n_splits(trainMat, trainLabels)\n",
    "sumAuc = 0.0\n",
    "for train_index, test_index in sfd.split(trainMat, labels):\n",
    "    X_train = trainMat[train_index]\n",
    "    y_train = trainLabels[train_index]\n",
    "    \n",
    "    X_test = trainMat[test_index]\n",
    "    y_test = trainLabels[test_index]\n",
    "    \n",
    "    MNB.fit(X_train, y_train)\n",
    "    auc = roc_auc_score(y_test, MNB.predict_proba(X_test)[:, 1])\n",
    "    sumAuc += auc\n",
    "    print(auc)\n",
    "print(\"ave Auc :\", sumAuc / 10.0)\n",
    "MNB.fit(trainMat, trainLabels)\n",
    "# 保存模型\n",
    "storeModel(MNB, 'MNB.txt')\n",
    "# 读取模型\n",
    "MNB = loadModel('MNB.txt')\n",
    "predictions = MNB.predict_proba(testMat)\n",
    "result = {'ID': range(1, len(predictions) + 1), \"Pred\": predictions[:, 1]}\n",
    "result = pd.DataFrame(result)\n",
    "\n",
    "result.to_csv('submit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
